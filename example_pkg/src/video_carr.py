# import cv2
# import numpy as np
# from ultralytics import YOLO

# # Carregar o modelo YOLO de segmenta√ß√£o
# model = YOLO("/home/filipe/catkin_ws/src/FIRA-Autonomous-Cars-Simulator/example_pkg/src/rede_neural/best.pt")

# # Caminho do v√≠deo de entrada
# video_path = "/home/filipe/catkin_ws/src/FIRA-Autonomous-Cars-Simulator/example_pkg/src/output.mp4"
# cap = cv2.VideoCapture(video_path)

# # Verificar se o v√≠deo abriu corretamente
# if not cap.isOpened():
#     print(f"‚ùå Erro ao abrir o v√≠deo: {video_path}")
#     exit()

# # Obter informa√ß√µes do v√≠deo original
# frame_width = int(cap.get(3))
# frame_height = int(cap.get(4))
# fps = int(cap.get(cv2.CAP_PROP_FPS))

# # Definir o codec e criar o objeto VideoWriter para salvar o v√≠deo
# output_path = "/home/filipe/catkin_ws/src/FIRA-Autonomous-Cars-Simulator/example_pkg/src/processed_video.mp4"
# fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec para MP4
# out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

# print("üé• Processando v√≠deo...")

# while True:
#     ret, frame = cap.read()
#     if not ret:
#         print("‚úÖ Fim do v√≠deo ou erro ao ler o frame.")
#         break

#     # Fazer a segmenta√ß√£o
#     results = model(frame)

#     # Criar uma m√°scara preta do mesmo tamanho do frame
#     mask = np.zeros(frame.shape[:2], dtype=np.uint8)

#     # Adicionar segmenta√ß√µes √† m√°scara
#     for result in results:
#         if result.masks is not None:
#             for segment in result.masks.xy:
#                 segment = np.array(segment, dtype=np.int32)
#                 cv2.fillPoly(mask, [segment], 255)  # Preenche com branco

#     # Aplicar opera√ß√£o morfol√≥gica para suavizar a m√°scara
#     kernel = np.ones((4, 4), np.uint8)
#     mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

#     # Converter a m√°scara para RGB e combin√°-la com o frame original
#     mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
#     processed_frame = cv2.addWeighted(frame, 0.7, mask_rgb, 0.3, 0)

#     # Escrever o frame processado no v√≠deo de sa√≠da
#     out.write(processed_frame)

# # Liberar recursos
# cap.release()
# out.release()
# print(f"‚úÖ V√≠deo processado salvo em: {output_path}")

import cv2
import numpy as np
from ultralytics import YOLO

# Carregar o modelo YOLO de segmenta√ß√£o
model = YOLO("example_pkg/src/rede_neural/best.pt")

# Carregar o v√≠deo
video_path = "example_pkg/src/output.mp4"  # Altere para o caminho do seu v√≠deo
cap = cv2.VideoCapture(video_path)

# Obter FPS e tamanho do v√≠deo para salvar o resultado
fps = int(cap.get(cv2.CAP_PROP_FPS))
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# Criar um arquivo de sa√≠da (opcional)
output_path = "output.avi"
fourcc = cv2.VideoWriter_fourcc(*"XVID")
out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

while cap.isOpened():
    ret, frame = cap.read()  # Captura um frame do v√≠deo
    if not ret:
        break  # Sai do loop se o v√≠deo terminou

    # Processa a imagem com o modelo YOLO
    results = model(frame)

    # Itera sobre as detec√ß√µes
    for result in results:
        masks = result.masks  # M√°scaras de segmenta√ß√£o
        boxes = result.boxes  # Caixas delimitadoras
        names = result.names  # Nomes das classes

        if masks is not None:
            for mask in masks.xy:
                mask = np.array(mask, dtype=np.int32)
                cv2.polylines(frame, [mask], isClosed=True, color=(0, 255, 0), thickness=2)  # Desenhar contorno
                cv2.fillPoly(frame, [mask], color=(0, 255, 0, 50))  # Preencher com transpar√™ncia

        if boxes is not None:
            for box in boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])  # Coordenadas da caixa
                conf = box.conf[0].item()  # Confian√ßa
                class_id = int(box.cls[0])  # Classe detectada
                label = f"{names[class_id]} {conf:.2f}"  # R√≥tulo da detec√ß√£o

                # Desenhar a caixa e r√≥tulo
                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    # Escrever no v√≠deo de sa√≠da
    out.write(frame)

    # Exibir a imagem processada
    # cv2.imshow("Detec√ß√£o YOLO", frame)

    # Pressionar 'q' para sair
    # if cv2.waitKey(1) & 0xFF == ord('q'):
        # break

cap.release()
out.release()
cv2.destroyAllWindows()
